# Decision Recruitment AI

Sistema de InteligÃªncia Artificial para prediÃ§Ã£o de match candidato-vaga usando XGBoost, desenvolvido para a Decision.

## VisÃ£o Geral

O **Decision Recruitment AI** Ã© uma soluÃ§Ã£o completa de Machine Learning que utiliza algoritmos de classificaÃ§Ã£o para prever a probabilidade de contrataÃ§Ã£o de candidatos, otimizando o processo de recrutamento da Decision.

### Objetivos

- **Automatizar** o processo de triagem inicial de candidatos
- **Otimizar** o match entre candidatos e vagas
- **Reduzir** o tempo de recrutamento
- **Aumentar** a precisÃ£o na seleÃ§Ã£o de candidatos
- **Fornecer** insights baseados em dados histÃ³ricos

## Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DADOS DE ENTRADA                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  vagas.json     prospects.json     applicants.json             â”‚
â”‚  14.081 vagas   14.222 prospecÃ§Ãµes  42.482 candidatos         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                   â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PIPELINE DE TREINAMENTO                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Dataset Unificado â†’ Feature Engineering â†’ OtimizaÃ§Ã£o          â”‚
â”‚  53.759 registros   28 features         Optuna + XGBoost      â”‚
â”‚                                            â†“                   â”‚
â”‚                                   Modelo Treinado              â”‚
â”‚                                   AUC: 0.7946                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MODELO PERSISTIDO                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  xgboost_model.pkl    label_encoders.pkl                       â”‚
â”‚  scaler.pkl          model_metadata.json                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         API FASTAPI                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  /predict        /predict_batch     /health      /debug         â”‚
â”‚  Individual      Lote               Status       Troubleshoot   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DEPLOYMENT                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Railway (ProduÃ§Ã£o)              Docker (Local/Staging)        â”‚
â”‚  https://decision-recruitment    Container local               â”‚
â”‚  .up.railway.app/                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MLFLOW TRACKING                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Experimentos    Model Registry    Feature Importance          â”‚
â”‚  MÃ©tricas        Versionamento     VisualizaÃ§Ã£o                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Dados

### Estrutura dos Dados

- **vagas.json**: 14.081 vagas com informaÃ§Ãµes detalhadas
- **prospects.json**: 14.222 prospecÃ§Ãµes de candidatos
- **applicants.json**: 42.482 candidatos com perfis completos

### Dataset Unificado

- **53.759 registros** de candidatos-vagas
- **Taxa de contrataÃ§Ã£o**: 5,55% (2.984 candidatos contratados de 50.775 total)
- **57 features** extraÃ­das e preparadas
- **28 features finais** apÃ³s feature engineering e otimizaÃ§Ã£o

## Features do Modelo

### Features de Compatibilidade
- Match de nÃ­vel profissional
- Compatibilidade de idiomas (inglÃªs/espanhol)
- Alinhamento de formaÃ§Ã£o acadÃªmica

### Features de AnÃ¡lise de Texto
- PresenÃ§a de palavras-chave tÃ©cnicas no CV
- CertificaÃ§Ãµes mencionadas
- Comprimento e qualidade do CV

### Features Temporais
- Tempo de resposta Ã  vaga
- CategorizaÃ§Ã£o temporal

### Features de Engagement
- Qualidade dos comentÃ¡rios
- PresenÃ§a de informaÃ§Ãµes de remuneraÃ§Ã£o
- Detalhamento das candidaturas

## InstalaÃ§Ã£o e Uso

### 1. Clone o RepositÃ³rio

```bash
git clone https://github.com/fontesmartins/datathon_fiap.git
cd fiap-final
```

### 2. Instalar DependÃªncias

```bash
pip install -r requirements.txt
```

### 3. Treinar o Modelo

```bash
python main.py
```

### 4. Executar API Localmente

```bash
python fastapi_app.py
```

### 5. Deploy com Docker

```bash
./deploy_linux.sh
```

## API Endpoints

### Base URL
```
http://localhost:8000
```

### Endpoints DisponÃ­veis

#### 1. Health Check
```http
GET /health
```

#### 2. PrediÃ§Ã£o Ãšnica
```http
POST /predict
Content-Type: application/json

{
"candidate": {
"nome": "JoÃ£o Silva",
"nivel_profissional_candidato": "SÃªnior",
"nivel_ingles_candidato": "AvanÃ§ado",
"nivel_espanhol_candidato": "IntermediÃ¡rio",
"cv_text": "Desenvolvedor Python com 5 anos de experiÃªncia...",
"pcd": "NÃ£o",
"remuneracao": 8000.0,
"estado": "SÃ£o Paulo"
},
"job": {
"titulo_vaga": "Desenvolvedor Python SÃªnior",
"nivel_profissional_vaga": "SÃªnior",
"nivel_ingles_vaga": "AvanÃ§ado",
"nivel_espanhol_vaga": "BÃ¡sico",
"vaga_sap": "NÃ£o",
"competencia_tecnicas": "Python, Django, Flask, AWS, Docker",
"tipo_contratacao": "CLT Full"
}
}
```

#### 3. PrediÃ§Ã£o em Lote
```http
POST /predict_batch
Content-Type: application/json

{
"candidates": [...],
"job": {...}
}
```

#### 4. InformaÃ§Ãµes do Modelo
```http
GET /model_info
```

#### 5. ImportÃ¢ncia das Features
```http
GET /feature_importance
```

### Resposta da API

```json
{
"prediction": 1,
"probability": 0.85,
"confidence": "High",
"recommendation": "RECOMENDADO",
"explanation": "Candidato tem alta compatibilidade com a vaga",
"timestamp": "2025-09-12T20:30:00",
"status": "success"
}
```

## Testes

### Testes da API
```bash
# Teste avanÃ§ado da API
python test_api_advanced.py

# Teste simples via script
./test_api.sh
```


## Performance do Modelo

### MÃ©tricas de Treinamento (Ãšltimo Treinamento)
- **AUC Score**: 0.7946 (79.46% de acurÃ¡cia)
- **CV AUC Score**: 0.7512 (Â±0.0779) - ValidaÃ§Ã£o cruzada
- **Taxa de ContrataÃ§Ã£o**: 5.55% (dataset desbalanceado)
- **Features Utilizadas**: 28 features otimizadas (removido data leakage)
- **Algoritmo**: XGBoost com otimizaÃ§Ã£o bayesiana (30 trials)
- **Data do Treinamento**: 28/09/2025
- **Melhorias**: Removidas variÃ¡veis `cliente` e `recrutador` para evitar data leakage

### Features Mais Importantes (Top 10)
1. `tipo_contratacao_encoded` - Tipo de contrataÃ§Ã£o (12.25%)
2. `nivel_ingles_x_encoded` - NÃ­vel de inglÃªs da vaga (10.15%)
3. `is_sp` - Candidato em SÃ£o Paulo (7.21%)
4. `nivel_espanhol_x_encoded` - NÃ­vel de espanhol da vaga (5.37%)
5. `cv_has_technical_keywords` - CV com palavras-chave tÃ©cnicas (4.36%)
6. `nivel_academico_x_encoded` - NÃ­vel acadÃªmico da vaga (4.30%)
7. `nivel_academico_y_encoded` - NÃ­vel acadÃªmico do candidato (4.08%)
8. `nivel_ingles_y_encoded` - NÃ­vel de inglÃªs do candidato (4.07%)
9. `area_atuacao_encoded` - Ãrea de atuaÃ§Ã£o (4.03%)
10. `nivel_ingles_compatibility` - Compatibilidade de inglÃªs (3.98%)

## Docker

### Construir Imagem
```bash
docker build -t decision-recruitment-ai:latest .
```

### Executar Container
```bash
docker run -d --name decision-recruitment-api -p 8000:8000 decision-recruitment-ai:latest
```

### Verificar Status
```bash
docker ps --filter name=decision-recruitment-api
```

### Ver Logs
```bash
docker logs decision-recruitment-api
```

## Status da API

### âœ… API Online e Funcionando
- **Railway**: https://decision-recruitment.up.railway.app/
- **Status**: âœ… Funcionando perfeitamente
- **Features**: âœ… 28 features corretas
- **PrediÃ§Ãµes**: âœ… Funcionando (individual e lote)
- **Ãšltima atualizaÃ§Ã£o**: 29/09/2025

### Teste RÃ¡pido
```bash
# Testar API
curl -X POST https://decision-recruitment.up.railway.app/predict \
  -H "Content-Type: application/json" \
  -d @test_prediction.json

# Verificar saÃºde
curl https://decision-recruitment.up.railway.app/health
```

## Monitoramento

### Logs de PrediÃ§Ãµes
- LocalizaÃ§Ã£o: `logs/predictions.log`
- Formato: JSON estruturado
- Inclui: timestamp, prediÃ§Ã£o, probabilidade, tempo de resposta

### MÃ©tricas
- LocalizaÃ§Ã£o: `logs/metrics.json`
- PerÃ­odo: Ãšltimas 24 horas
- Inclui: taxa de recomendaÃ§Ã£o, confianÃ§a, tempo de resposta

### DetecÃ§Ã£o de Drift
- ComparaÃ§Ã£o com baseline
- Alertas automÃ¡ticos
- Threshold configurÃ¡vel

## DocumentaÃ§Ã£o da API

Acesse a documentaÃ§Ã£o interativa em:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## Estrutura do Projeto

```
fiap-final/
README.md # Este arquivo
requirements.txt # DependÃªncias Python (inclui MLflow)
Dockerfile # ConfiguraÃ§Ã£o Docker
.dockerignore # Arquivos ignorados no Docker
main.py # Pipeline de treinamento (com MLflow)
fastapi_app.py # API FastAPI (com MLflow logging)
test_api_advanced.py # Testes avanÃ§ados da API
test_api.sh # Script de teste simples
# monitoring.py removido (nÃ£o funcional)
deploy_linux.sh # Script de deploy para Linux
data_analysis.py # AnÃ¡lise inicial dos dados
mlflow_config.py # ConfiguraÃ§Ã£o MLflow
# mlflow_experiments.py removido (obsoleto)
validate_docker_linux.py # Validador Docker para Linux
models/ # Modelos treinados
xgboost_model.pkl
label_encoders.pkl
scaler.pkl
model_metadata.json
mlruns/ # MLflow tracking data
0/ # Experimento padrÃ£o
[experiment_id]/ # Experimentos especÃ­ficos
logs/ # Logs do sistema
predictions.log
metrics.json
dataset_preparado.csv # Dataset processado
```

## Casos de Uso

### 1. Triagem AutomÃ¡tica
- Classificar candidatos automaticamente
- Priorizar candidatos com maior probabilidade
- Reduzir tempo de anÃ¡lise manual

### 2. AnÃ¡lise de Compatibilidade
- Avaliar match tÃ©cnico
- Verificar alinhamento cultural
- Identificar gaps de competÃªncias

### 3. Insights de Recrutamento
- Identificar padrÃµes de sucesso
- Otimizar descriÃ§Ãµes de vagas
- Melhorar processo de seleÃ§Ã£o

## MLflow Integration

O projeto agora inclui integraÃ§Ã£o completa com MLflow para experimentaÃ§Ã£o, tracking e versionamento de modelos.

### Iniciando MLflow

```bash
# Iniciar MLflow UI
python start_mlflow.py

# Ou manualmente
mlflow ui --backend-store-uri file:./mlruns
# Acesse: http://localhost:5000
```

### Funcionalidades MLflow

#### 1. **Experiment Tracking**
- Rastreamento automÃ¡tico de parÃ¢metros e mÃ©tricas
- ComparaÃ§Ã£o de diferentes configuraÃ§Ãµes de modelo
- VisualizaÃ§Ã£o de resultados em tempo real

#### 2. **Model Registry**
- Versionamento automÃ¡tico de modelos
- GestÃ£o de stages (Staging, Production, Archived)
- Deploy automÃ¡tico do melhor modelo

#### 3. **Experimentos Automatizados**
```bash
# Executar suite completa de experimentos
# python mlflow_experiments.py (arquivo removido)

# Treinar modelo com MLflow tracking
python main.py
```

#### 4. **API Integration**
- Logging automÃ¡tico de prediÃ§Ãµes em produÃ§Ã£o
- MÃ©tricas de performance em tempo real
- Endpoint `/mlflow_info` para informaÃ§Ãµes do MLflow
- Endpoint `/debug` para troubleshooting

#### 5. **Monitoramento AvanÃ§ado**
```bash
# Monitorar sistema completo (incluindo MLflow)
# python monitoring.py (arquivo removido)
```

### Experimentos DisponÃ­veis

1. **Hyperparameter Tuning**: Testa diferentes configuraÃ§Ãµes do XGBoost
2. **Model Comparison**: Compara XGBoost, Random Forest e Logistic Regression
3. **Feature Analysis**: Analisa importÃ¢ncia das features
4. **Production Logging**: Registra prediÃ§Ãµes em tempo real


## PrÃ³ximos Passos

### Melhorias Planejadas
- [x] **MLflow Integration** - Experiment tracking e model registry âœ…
- [ ] Interface web para usuÃ¡rios
- [ ] Modelo de recomendaÃ§Ã£o de vagas
- [ ] AnÃ¡lise de sentimento em CVs
- [ ] Dashboard de mÃ©tricas em tempo real

### ExpansÃµes
- [ ] Suporte a mais tipos de vaga
- [ ] IntegraÃ§Ã£o com LinkedIn API

## ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature
3. Commit suas mudanÃ§as
4. Push para a branch
5. Abra um Pull Request

## ExecuÃ§Ã£o RÃ¡pida

### 1. Treinamento do Modelo
```bash
python main.py
```
**Resultados esperados:**
- Modelo salvo em `models/`
- OtimizaÃ§Ã£o de hiperparÃ¢metros (30 trials)
- Logs do MLflow em `mlruns/`
- AUC Score: ~0.79

### 2. Executar API
```bash
python fastapi_app.py
```
**Endpoints disponÃ­veis:**
- `GET /health` - Health check
- `POST /predict` - PrediÃ§Ã£o individual
- `POST /predict_batch` - PrediÃ§Ã£o em lote
- `GET /model_info` - InformaÃ§Ãµes do modelo
- `GET /feature_importance` - ImportÃ¢ncia das features
- `GET /mlflow_info` - InformaÃ§Ãµes do MLflow
- `GET /debug` - Debug e troubleshooting

### 3. Testar API
```bash
# Health check
curl http://localhost:8000/health

# PrediÃ§Ã£o
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d @test_prediction.json
```

### 4. Deploy com Docker
```bash
./deploy_linux.sh
```

## DocumentaÃ§Ã£o Completa

Para informaÃ§Ãµes detalhadas sobre arquitetura, uso da API, MLflow, troubleshooting e mais:

**[ğŸ“š DocumentaÃ§Ã£o Completa](DOCUMENTACAO.md)**

## LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## Equipe

- **Desenvolvedor**: [Seu Nome]
- **InstituiÃ§Ã£o**: FIAP

## Suporte

Para dÃºvidas ou suporte:
- Email: ezequiel.martins2@icloud.com
- LinkedIn: https://www.linkedin.com/in/fontesmartins23/
- GitHub: https://github.com/fontesmartins/

---