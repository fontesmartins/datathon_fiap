# üöÄ Guia de Execu√ß√£o - Decision Recruitment AI

## üìã Vis√£o Geral

Este documento explica a ordem de execu√ß√£o e funcionamento de cada m√≥dulo do sistema Decision Recruitment AI, um sistema de match candidato-vaga usando Machine Learning com XGBoost e MLflow.

## üéØ Ordem de Execu√ß√£o

### 1. **main.py** - Pipeline Principal
**Arquivo principal que executa todo o fluxo de treinamento**

#### Classe: `DecisionRecruitmentPipeline`

##### M√©todos principais:

**`__init__(self)`**
- Inicializa a pipeline
- Configura MLflow, scaler, encoders e listas de features
- Cria inst√¢ncia do MLflow config

**`load_and_prepare_data(self)`**
- Carrega dataset de `dataset_preparado.csv`
- Aplica feature engineering b√°sico
- Prepara features num√©ricas e categ√≥ricas
- Codifica vari√°veis categ√≥ricas
- Retorna X (features) e y (target)

**`basic_feature_engineering(self, df)`**
- Cria features de compatibilidade (n√≠vel profissional, idiomas)
- Gera features de texto (CV analysis)
- Calcula features b√°sicas (SAP, PCD, localiza√ß√£o)
- Cria features de match (compatibilidade exata)
- Retorna DataFrame com novas features

**`prepare_features(self, df)`**
- Define lista de features num√©ricas (16 features)
- Define lista de features categ√≥ricas (14 features)
- Filtra colunas que existem no dataset

**`encode_categorical_features(self, df)`**
- Aplica LabelEncoder em cada feature categ√≥rica
- Cria colunas `_encoded` para cada categoria
- Salva encoders para uso posterior

**`prepare_training_data(self, df)`**
- Filtra features v√°lidas
- Remove linhas com target nulo
- Identifica vari√°veis cont√≠nuas
- Aplica normaliza√ß√£o (StandardScaler)
- Retorna X e y prontos para treinamento

**`identify_continuous_variables(self, X)`**
- Identifica vari√°veis que t√™m valores decimais
- Retorna lista de vari√°veis cont√≠nuas para normaliza√ß√£o

**`optimize_hyperparameters(self, X, y, n_trials=50)`**
- Executa otimiza√ß√£o bayesiana com Optuna
- Testa 30 combina√ß√µes de hiperpar√¢metros
- Usa valida√ß√£o holdout (80% treino, 20% valida√ß√£o)
- Salva melhores par√¢metros em `optimization_results.json`
- Retorna par√¢metros otimizados e melhor score

**`train_final_model(self, X, y, best_params)`**
- Treina modelo final com par√¢metros otimizados
- Usa MLflow para logging de par√¢metros e m√©tricas
- Executa valida√ß√£o cruzada (5-fold)
- Loga import√¢ncia das features
- Registra modelo no MLflow
- Retorna m√©tricas de performance

**`save_model(self)`**
- Salva modelo XGBoost em `models/xgboost_model.pkl`
- Salva encoders em `models/label_encoders.pkl`
- Salva scaler em `models/scaler.pkl`
- Salva metadados em `models/model_metadata.json`

**`register_model_in_mlflow(self)`**
- Registra modelo no MLflow Model Registry
- Define stage como "Production"
- Retorna status do registro

**`main()`**
- Fun√ß√£o principal que orquestra todo o pipeline
- Executa: carregamento ‚Üí otimiza√ß√£o ‚Üí treinamento ‚Üí salvamento ‚Üí registro
- Retorna pipeline e resultados

---

### 2. **mlflow_config.py** - Configura√ß√£o MLflow
**Gerencia configura√ß√£o e opera√ß√µes do MLflow**

#### Classe: `MLflowConfig`

##### M√©todos principais:

**`__init__(self, experiment_name, tracking_uri, registry_uri)`**
- Configura tracking URI (file:./mlruns)
- Cria ou obt√©m experimento
- Define experimento ativo

**`setup_mlflow(self)`**
- Configura tracking e registry URIs
- Cria experimento se n√£o existir
- Define experimento ativo

**`start_run(self, run_name, tags)`**
- Inicia novo run do MLflow
- Adiciona tags padr√£o (project, model_type, created_at)
- Retorna contexto do run

**`log_model_params(self, params)`**
- Loga par√¢metros do modelo no MLflow
- Registra quantidade de par√¢metros

**`log_model_metrics(self, metrics)`**
- Loga m√©tricas do modelo
- Registra lista de m√©tricas logadas

**`log_model_artifacts(self, artifacts)`**
- Loga arquivos como artefatos
- Verifica exist√™ncia dos arquivos

**`log_xgboost_model(self, model, model_name, signature, input_example)`**
- Loga modelo XGBoost no MLflow
- Registra modelo com nome "decision-recruitment-model"
- Inclui signature e input example

**`log_feature_importance(self, feature_names, importance_scores)`**
- Cria DataFrame com import√¢ncia das features
- Loga como artefato CSV
- Loga top 10 features como m√©tricas

**`log_dataset_info(self, dataset_path, target_column)`**
- Loga informa√ß√µes do dataset
- Calcula m√©tricas: linhas, colunas, distribui√ß√£o target, valores nulos
- Loga dataset como artefato

**`register_model(self, model_name, model_version, stage)`**
- Registra modelo no Model Registry
- Transiciona para stage especificado (Production)
- Retorna modelo registrado

**`load_model(self, model_name, stage)`**
- Carrega modelo do Model Registry
- Usa URI: models:/{model_name}/{stage}
- Retorna modelo carregado

---

### 3. **fastapi_app.py** - API REST
**Interface REST para predi√ß√µes do modelo**

#### Endpoints principais:

**`load_model()`**
- Carrega modelo na inicializa√ß√£o da API
- Tenta carregar do MLflow Registry primeiro
- Fallback para modelo local se necess√°rio
- Configura MLflow para logging de predi√ß√µes

**`preprocess_input(candidate_data, job_data)`**
- Preprocessa dados de entrada da API
- Aplica feature engineering b√°sico
- Cria DataFrame com features necess√°rias
- Preenche features ausentes com 0

**`apply_basic_feature_engineering(df)`**
- Aplica mesmo feature engineering do treinamento
- Calcula compatibilidades (n√≠vel, idiomas)
- Analisa texto do CV
- Cria features de match

**`@app.on_event("startup")`**
- Evento de inicializa√ß√£o da aplica√ß√£o
- Carrega modelo automaticamente
- Falha se modelo n√£o puder ser carregado

**`@app.get("/health")`**
- Endpoint de health check
- Retorna status da aplica√ß√£o e modelo

**`@app.post("/predict")`**
- Endpoint principal de predi√ß√£o
- Recebe dados do candidato e vaga
- Preprocessa dados
- Faz predi√ß√£o com modelo
- Determina confian√ßa e recomenda√ß√£o
- Loga predi√ß√£o no MLflow
- Retorna resposta estruturada

**`@app.post("/predict_batch")`**
- Endpoint para predi√ß√£o em lote
- Processa m√∫ltiplos candidatos para uma vaga
- Retorna lista de resultados

**`@app.get("/model_info")`**
- Retorna informa√ß√µes do modelo
- Carrega metadados do arquivo JSON
- Lista features e configura√ß√µes

**`@app.get("/feature_importance")`**
- Retorna import√¢ncia das features
- Ordena por import√¢ncia decrescente
- Retorna top 20 features

**`@app.get("/mlflow_info")`**
- Retorna informa√ß√µes do MLflow
- Lista runs recentes
- Mostra m√©tricas dos experimentos

---

### 4. **monitoring.py** - Sistema de Monitoramento
**Monitora performance e sa√∫de do sistema**

#### Classes principais:

**`ModelMonitor`**
- Monitor de predi√ß√µes e m√©tricas
- Detecta drift no modelo
- Gera relat√≥rios de performance

**`MLflowMonitor`**
- Monitor espec√≠fico do MLflow
- Obt√©m m√©tricas dos experimentos
- Monitora Model Registry

**`APIMonitor`**
- Monitor da API REST
- Testa endpoints
- Verifica sa√∫de da aplica√ß√£o

##### M√©todos principais:

**`log_prediction(prediction_data, response_time_ms, model_version)`**
- Registra predi√ß√£o no log estruturado
- Salva timestamp, candidato, resultado, tempo de resposta

**`calculate_metrics(time_window_hours)`**
- Calcula m√©tricas agregadas
- Taxa de recomenda√ß√£o, confian√ßa, tempo de resposta
- Retorna objeto ModelMetrics

**`detect_drift(baseline_metrics, current_metrics, threshold)`**
- Detecta drift comparando m√©tricas
- Compara taxa de recomenda√ß√£o, probabilidade m√©dia
- Retorna detalhes do drift detectado

**`generate_report(time_window_hours)`**
- Gera relat√≥rio completo de monitoramento
- Inclui m√©tricas, status do sistema, recomenda√ß√µes

**`get_experiment_metrics()`**
- Obt√©m m√©tricas dos experimentos MLflow
- Calcula m√©dias de AUC, tempo de execu√ß√£o
- Conta runs bem-sucedidos vs falhados

**`check_api_health()`**
- Verifica sa√∫de da API
- Testa endpoint /health
- Mede tempo de resposta

**`test_prediction_endpoint()`**
- Testa endpoint de predi√ß√£o
- Usa dados de teste
- Loga resultado no sistema de monitoramento

---

### 5. **model_pipeline.py** - Pipeline Avan√ßado
**Pipeline mais complexo com feature engineering avan√ßado**

#### Classe: `DecisionRecruitmentModel`

##### M√©todos principais:

**`advanced_feature_engineering(self)`**
- Feature engineering mais sofisticado
- Cria features de compatibilidade t√©cnica
- An√°lise de texto avan√ßada
- Features temporais
- Features de engagement
- Scores de match global

**`optimize_hyperparameters(self, X, y, n_trials, val_size, use_mlflow)`**
- Otimiza√ß√£o bayesiana com Optuna
- Integra√ß√£o com MLflow callback
- Holdout validation
- Salva resultados em JSON

**`train_model(self, X, y, test_size, val_size, use_mlflow, use_optimized_params)`**
- Treinamento com 3 folds (treino/valida√ß√£o/teste)
- Usa par√¢metros otimizados se dispon√≠vel
- Logging completo no MLflow
- Valida√ß√£o cruzada

**`identify_continuous_variables(self, X)`**
- Identifica vari√°veis cont√≠nuas vs discretas
- Crit√©rio: presen√ßa de valores decimais
- Usado para normaliza√ß√£o seletiva

**`apply_normalization(self, X, continuous_vars, fit_scaler)`**
- Aplica StandardScaler apenas em vari√°veis cont√≠nuas
- Preserva vari√°veis discretas sem normaliza√ß√£o
- Ajusta scaler apenas no treinamento

---

### 6. **mlflow_experiments.py** - Experimentos MLflow
**Script para executar experimentos comparativos**

#### Classe: `MLflowExperimentRunner`

##### M√©todos principais:

**`run_hyperparameter_experiment(self, X, y)`**
- Executa grid search de hiperpar√¢metros
- Testa 20 combina√ß√µes diferentes
- Loga cada experimento no MLflow
- Retorna melhores par√¢metros

**`run_model_comparison_experiment(self, X, y)`**
- Compara diferentes algoritmos
- Testa: XGBoost, Random Forest, Logistic Regression
- Loga cada modelo no MLflow
- Retorna resultados comparativos

**`run_feature_importance_experiment(self, X, y)`**
- Analisa import√¢ncia das features
- Loga top features como m√©tricas
- Cria visualiza√ß√µes de import√¢ncia

**`run_all_experiments(self)`**
- Executa suite completa de experimentos
- Orquestra todos os experimentos
- Gera relat√≥rio final

---

## üîÑ Fluxo de Execu√ß√£o Completo

### 1. **Prepara√ß√£o**
```bash
# Instalar depend√™ncias
pip install -r requirements.txt
```

### 2. **Execu√ß√£o do Pipeline**
```bash
# Executar pipeline completo
python main.py
```

**O que acontece:**
1. Carrega dados de `dataset_preparado.csv`
2. Aplica feature engineering
3. Executa otimiza√ß√£o de hiperpar√¢metros (30 trials)
4. Treina modelo final com par√¢metros otimizados
5. Salva modelo em `models/`
6. Registra modelo no MLflow
7. Loga todas as m√©tricas e artefatos

### 3. **Inicializa√ß√£o da API**
```bash
# Iniciar API REST
python fastapi_app.py
```

**O que acontece:**
1. Carrega modelo treinado
2. Configura endpoints REST
3. Inicia servidor na porta 8000
4. Disponibiliza interface de predi√ß√£o

### 4. **Monitoramento**
```bash
# Executar monitoramento
python monitoring.py
```

**O que acontece:**
1. Verifica sa√∫de da API
2. Testa endpoints
3. Calcula m√©tricas de performance
4. Monitora MLflow
5. Gera relat√≥rio de status

### 5. **Visualiza√ß√£o MLflow**
```bash
# Iniciar MLflow UI
mlflow ui --backend-store-uri file:./mlruns
```

**O que acontece:**
1. Inicia interface web do MLflow
2. Disponibiliza em http://localhost:5000
3. Mostra experimentos, runs, m√©tricas
4. Permite navegar pelo Model Registry

---

## üìä Resultados Esperados

### M√©tricas de Performance
- **AUC Score**: ~83% (ap√≥s otimiza√ß√£o)
- **CV AUC**: ~77% (¬±9%)
- **Features**: 30 features otimizadas
- **Tempo de treinamento**: ~2-3 minutos

### Arquivos Gerados
- `models/xgboost_model.pkl` - Modelo treinado
- `models/label_encoders.pkl` - Encoders categ√≥ricos
- `models/scaler.pkl` - Normalizador
- `models/model_metadata.json` - Metadados
- `optimization_results.json` - Par√¢metros otimizados
- `mlruns/` - Tracking do MLflow

### API Endpoints
- `GET /health` - Status da aplica√ß√£o
- `POST /predict` - Predi√ß√£o individual
- `POST /predict_batch` - Predi√ß√£o em lote
- `GET /model_info` - Informa√ß√µes do modelo
- `GET /feature_importance` - Import√¢ncia das features
- `GET /mlflow_info` - Status do MLflow

---

## üéØ Pr√≥ximos Passos

1. **Deploy**: Usar `deploy.py` para deploy em produ√ß√£o
2. **Monitoramento**: Configurar alertas de drift
3. **Retreinamento**: Automatizar retreinamento peri√≥dico
4. **A/B Testing**: Implementar testes de modelos
5. **CI/CD**: Integrar com pipeline de CI/CD

---

## üö® Troubleshooting

### Problemas Comuns

**MLflow UI n√£o inicia:**
```bash
# Tentar porta diferente
mlflow ui --backend-store-uri file:./mlruns --port 5001
```

**API n√£o carrega modelo:**
- Verificar se `models/` existe
- Verificar se `model_metadata.json` est√° presente
- Verificar logs da API

**Otimiza√ß√£o falha:**
- Verificar se dataset existe
- Verificar mem√≥ria dispon√≠vel
- Reduzir `n_trials` se necess√°rio

**Predi√ß√µes inconsistentes:**
- Verificar se feature engineering √© id√™ntico
- Verificar se encoders est√£o sendo aplicados
- Verificar se normaliza√ß√£o est√° sendo aplicada

---

## üìö Refer√™ncias

- [MLflow Documentation](https://mlflow.org/docs/)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [Optuna Documentation](https://optuna.readthedocs.io/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
